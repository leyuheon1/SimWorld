{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from simworld.config import Config\n",
    "from simworld.communicator.communicator import Communicator\n",
    "from simworld.communicator.unrealcv import UnrealCV\n",
    "from simworld.traffic.controller.traffic_controller import TrafficController\n",
    "from simworld.traffic.base.traffic_signal import TrafficSignalState\n",
    "from simworld.llm.a2a_llm import A2ALLM\n",
    "from simworld.llm.base_llm import BaseLLM\n",
    "from simworld.map.map import Map\n",
    "from simworld.agent.humanoid import Humanoid\n",
    "from simworld.utils.vector import Vector\n",
    "from simworld.local_planner.local_planner import LocalPlanner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communicator = Communicator(UnrealCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '<your_openai_api_key_here>'  # Replace with your actual OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, goal):\n",
    "        self.goal = goal\n",
    "        self.llm = BaseLLM(\"gpt-4o\")\n",
    "        self.system_prompt = f\"You are an intelligent agent in a 3D world. Your goal is to: {self.goal}.\"\n",
    "\n",
    "    def action(self, obs):\n",
    "        prompt = f\"{self.system_prompt}\\n You are currently at: {obs}\\nWhat is your next goal?\"\n",
    "        action = self.llm.generate_text(system_prompt=self.system_prompt, user_prompt=prompt)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, communicator, config=Config()):\n",
    "        self.communicator = communicator\n",
    "        self.agent = None\n",
    "        self.target = None\n",
    "        self.action_planner = None\n",
    "        self.config = config\n",
    "        self.action_planner_llm = A2ALLM(model_name=\"gpt-4o-mini\")\n",
    "        self.map = Map(config)\n",
    "        self.map.initialize_map_from_file(roads_file= os.path.join('../data/sample_data/road.json')) # use default map\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Clear the UE scene and (re)spawn the humanoid and target.\"\"\"\n",
    "        # Clear spawned objects\n",
    "        self.communicator.clear_env()\n",
    "\n",
    "        # Blueprint path for the humanoid agent to spawn in the UE level\n",
    "        agent_bp = \"/Game/TrafficSystem/Pedestrian/Base_User_Agent.Base_User_Agent_C\"\n",
    "\n",
    "        # Initial spawn position and facing direction for the humanoid (2D)\n",
    "        spawn_location = Vector(0, 0)\n",
    "        spawn_forward = Vector(0, 1)\n",
    "        self.agent = Humanoid(\n",
    "            communicator=self.communicator,\n",
    "            position=spawn_location,\n",
    "            direction=spawn_forward,\n",
    "            config=self.config,\n",
    "            map=self.map\n",
    "        )\n",
    "\n",
    "        self.action_planner = LocalPlanner(\n",
    "            agent=self.agent,\n",
    "            model=self.action_planner_llm,\n",
    "            rule_based=False)\n",
    "\n",
    "        # Spawn the humanoid agent in the Unreal world\n",
    "        # NOTE: name is ignored for humanoid type, but required by the API.\n",
    "        self.communicator.spawn_agent(self.agent, name=None, model_path=agent_bp, type=\"humanoid\")\n",
    "\n",
    "        # Cache the generated UE actor name\n",
    "        self.agent_name = self.communicator.get_humanoid_name(self.agent.id)\n",
    "\n",
    "        # Define a target position the agent is encouraged to move toward (example value)\n",
    "        self.target = Vector(1000, 0)\n",
    "\n",
    "        # Return initial observation\n",
    "        # observation = self.communicator.get_camera_observation(self.agent.camera_id, \"lit\")\n",
    "        observation = self.communicator.unrealcv.get_location(self.agent_name)\n",
    "        return observation\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Use action planner to execute the given action.\"\"\"\n",
    "        # Parse the action text and map it to the action space\n",
    "        primitive_actions = self.action_planner.parse(action)\n",
    "        self.action_planner.execute(primitive_actions)\n",
    "\n",
    "        # Get current location from UE (x, y, z) and convert to 2D Vector\n",
    "        loc_3d = self.communicator.unrealcv.get_location(self.agent_name)\n",
    "        # loc_3d is a numpy array; explicitly use x, y to build our 2D Vector\n",
    "        location = Vector(loc_3d[0], loc_3d[1])\n",
    "\n",
    "        # Camera observation for RL\n",
    "        observation = location\n",
    "\n",
    "        # Reward: negative Euclidean distance in 2D plane\n",
    "        reward = -location.distance(self.target)\n",
    "\n",
    "        return observation, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gym-like Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(goal='Go to (1700, -1700) and pick up GEN_BP_Box_1_C.')\n",
    "env = Environment(communicator)\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "# Roll out a short trajectory\n",
    "for _ in range(100):\n",
    "    action = agent.action(obs)\n",
    "    obs, reward = env.step(action)\n",
    "    print(f\"obs: {obs}, reward: {reward}\")\n",
    "    # Plug this into your RL loop / logging as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communicator.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
